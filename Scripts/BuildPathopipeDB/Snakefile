import pandas as pd
import glob
import os


## --------------------------------------------------------------------------------
## helpers

unit_df = pd.read_table("refs.tsv", comment="#").set_index(
    ["assemblyId"], drop=False
)
REFS = unit_df.index.unique()

KMER_LEN = 29 ## kmer-length for DB


## --------------------------------------------------------------------------------
## functions

def get_fasta(wildcards):
    return unit_df.loc[(wildcards.ref), "fasta"]


def get_mask_bed(wildcards):
    f = unit_df.loc[(wildcards.ref), "fasta"]
    return os.path.dirname(f) + "/{wildcards.ref}.sdust.bed"



## --------------------------------------------------------------------------------
## file sets

taxonomy_all = ["taxonomy/names.dmp", "taxonomy/nodes.dmp"]
bt2_all = [f"bt2/{ref}.{suffix}.bt2" for ref in REFS for suffix in ["1","2","3","4","rev.1","rev.2"]]
tables_all = ["taxLists/genus.taxIds.tsv.gz", "taxLists/species.taxIds.tsv.gz", "library.seqInfo.tsv"]


## --------------------------------------------------------------------------------
## targets

rule all:
    input:
        taxonomy_all + mmi_all + tables_all

        
## --------------------------------------------------------------------------------
## rules

rule get_genome_bed:
    input:
        get_fasta
    output:
        "library/{ref}.genome.bed"
    shell:
        """
        seqtk comp {input} | awk '{{print $1"\\t0\\t"$2}}' > {output}
        """

rule get_mask:
    input:
        fa=get_fasta,
        bed="library/{ref}.genome.bed"
    output:
        "library/{ref}.sdust.bed"
    shell:
        """
        sdust -t 30 {input} | bedtools intersect -a stdin -b {input.bed}> {output}
        """

rule mask_fasta:
    input:
        fa=get_fasta,
        bed="library/{ref}.sdust.bed"
    output:
        "library/{ref}.masked_sdust.fna"
    shell:
        """
        bedtools maskfasta -fi {input.fa} -bed {input.bed} -fo {output}
        """

rule tar_fasta:
    input:
        unit_df["fasta"]
    output:
        "library/fastas_raw.tar.gz"
    shell:
        """
        tar cvzf {output} {input}
        """

rule index_mmi:
    input:
        "library/{ref}.masked_sdust.fna"
    output:
        lambda wildcards: [f"bt2/{wildcards.ref}.{i}.bt2" for i in ["1","2","3","4","rev.1","rev.2"]]
    log:
        "logs/{ref}.index_mmi.log"
    threads: 12
    shell:
        """
        (bowtie2-build --seed 42 --threads {threads} {input} bt2/{wildcards.ref}) 2> {log}
        """
        ## building bowtie2 index 

        
rule download_taxonomy:
    output:
        "taxonomy/names.dmp",
        "taxonomy/nodes.dmp"
    shell:
        """
        krakenuniq-download --db `pwd` taxonomy
        """


rule build_db:
    input:
        expand("library/{ref}.masked_sdust.fna", ref=REFS),
        "taxonomy/names.dmp",
        "taxonomy/nodes.dmp"
    output:
        "taxDB",
        "database.kdb",
        "database.idx"
    log:
        "logs/krakenuniq_db_build.log"
    threads:
        24
    shell:
        """
        (krakenuniq-build --db `pwd` --taxids-for-genomes --taxids-for-sequences -kmer-len {KMER_LEN} --threads {threads} --jellyfish-bin /projects/mjolnir1/apps/conda/krakenuniq-1.0.3/bin/jellyfish) 2> {log}
        """
        
rule get_taxinfo:
    input:
        "taxDB"
    output:
        "taxLists/genus.taxIds.tsv.gz",
        "taxLists/species.taxIds.tsv.gz"
    threads:
        24
    shell:
        """
        Rscript src/getTaxInfo.R {threads}
        """

        
rule get_libinfo:
    input:
        "taxLists/genus.taxIds.tsv.gz",
        "taxLists/species.taxIds.tsv.gz"
    output:
        "library.seqInfo.tsv"
    threads:
        24
    shell:
        """
        Rscript src/getLibInfo.R {threads}
        """

